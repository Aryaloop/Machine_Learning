{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aryaa\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting the id and Unnamed: 32 columns\n",
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing With The Outliers\n",
    "numerical_columns = df.select_dtypes(exclude=object).columns.tolist()\n",
    "\n",
    "for col in numerical_columns:\n",
    "    upper_limit = df[col].mean() + 3 * df[col].std()\n",
    "    lower_limit = df[col].mean() - 3 * df[col].std()\n",
    "    df = df[(df[col] <= upper_limit) & (df[col] >= lower_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.519822</td>\n",
       "      <td>18.594778</td>\n",
       "      <td>87.363021</td>\n",
       "      <td>586.938407</td>\n",
       "      <td>0.093941</td>\n",
       "      <td>0.086810</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>0.037804</td>\n",
       "      <td>0.174981</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>15.276829</td>\n",
       "      <td>24.808290</td>\n",
       "      <td>99.807939</td>\n",
       "      <td>753.006323</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.207168</td>\n",
       "      <td>0.209125</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>0.278044</td>\n",
       "      <td>0.079029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.746168</td>\n",
       "      <td>3.926129</td>\n",
       "      <td>18.622502</td>\n",
       "      <td>251.365868</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.034808</td>\n",
       "      <td>0.050773</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>...</td>\n",
       "      <td>3.569692</td>\n",
       "      <td>5.652044</td>\n",
       "      <td>24.268222</td>\n",
       "      <td>372.056673</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>0.101980</td>\n",
       "      <td>0.141360</td>\n",
       "      <td>0.051527</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.011726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.034320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.055210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.665000</td>\n",
       "      <td>15.790000</td>\n",
       "      <td>74.720000</td>\n",
       "      <td>416.700000</td>\n",
       "      <td>0.084790</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>...</td>\n",
       "      <td>12.975000</td>\n",
       "      <td>20.535000</td>\n",
       "      <td>83.715000</td>\n",
       "      <td>513.500000</td>\n",
       "      <td>0.114350</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.097890</td>\n",
       "      <td>0.061315</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.070210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.030000</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>84.070000</td>\n",
       "      <td>520.200000</td>\n",
       "      <td>0.093450</td>\n",
       "      <td>0.079520</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.060820</td>\n",
       "      <td>...</td>\n",
       "      <td>14.380000</td>\n",
       "      <td>24.640000</td>\n",
       "      <td>93.850000</td>\n",
       "      <td>630.500000</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.085420</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.835000</td>\n",
       "      <td>20.975000</td>\n",
       "      <td>96.170000</td>\n",
       "      <td>674.650000</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.109950</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>0.053725</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.064160</td>\n",
       "      <td>...</td>\n",
       "      <td>16.765000</td>\n",
       "      <td>28.455000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>861.750000</td>\n",
       "      <td>0.141850</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.085510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.370000</td>\n",
       "      <td>30.720000</td>\n",
       "      <td>141.300000</td>\n",
       "      <td>1386.000000</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.078180</td>\n",
       "      <td>...</td>\n",
       "      <td>25.370000</td>\n",
       "      <td>41.610000</td>\n",
       "      <td>166.800000</td>\n",
       "      <td>1956.000000</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   427.000000    427.000000      427.000000   427.000000   \n",
       "mean     13.519822     18.594778       87.363021   586.938407   \n",
       "std       2.746168      3.926129       18.622502   251.365868   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.665000     15.790000       74.720000   416.700000   \n",
       "50%      13.030000     18.240000       84.070000   520.200000   \n",
       "75%      14.835000     20.975000       96.170000   674.650000   \n",
       "max      21.370000     30.720000      141.300000  1386.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       427.000000        427.000000      427.000000           427.000000   \n",
       "mean          0.093941          0.086810        0.062108             0.037804   \n",
       "std           0.012244          0.034808        0.050773             0.027837   \n",
       "min           0.062510          0.019380        0.000000             0.000000   \n",
       "25%           0.084790          0.059735        0.025590             0.018690   \n",
       "50%           0.093450          0.079520        0.045680             0.028640   \n",
       "75%           0.102300          0.109950        0.086975             0.053725   \n",
       "max           0.129100          0.202200        0.254500             0.132200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     427.000000              427.000000  ...    427.000000   \n",
       "mean        0.174981                0.061224  ...     15.276829   \n",
       "std         0.021885                0.005053  ...      3.569692   \n",
       "min         0.116700                0.049960  ...      7.930000   \n",
       "25%         0.159600                0.057250  ...     12.975000   \n",
       "50%         0.173500                0.060820  ...     14.380000   \n",
       "75%         0.189400                0.064160  ...     16.765000   \n",
       "max         0.254000                0.078180  ...     25.370000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     427.000000       427.000000   427.000000        427.000000   \n",
       "mean       24.808290        99.807939   753.006323          0.128976   \n",
       "std         5.652044        24.268222   372.056673          0.019843   \n",
       "min        12.020000        50.410000   185.200000          0.081250   \n",
       "25%        20.535000        83.715000   513.500000          0.114350   \n",
       "50%        24.640000        93.850000   630.500000          0.128900   \n",
       "75%        28.455000       112.000000   861.750000          0.141850   \n",
       "max        41.610000       166.800000  1956.000000          0.190900   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         427.000000       427.000000            427.000000   \n",
       "mean            0.207168         0.209125              0.097371   \n",
       "std             0.101980         0.141360              0.051527   \n",
       "min             0.034320         0.000000              0.000000   \n",
       "25%             0.134800         0.097890              0.061315   \n",
       "50%             0.188000         0.181000              0.085420   \n",
       "75%             0.263900         0.307000              0.133700   \n",
       "max             0.560900         0.639900              0.254300   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      427.000000               427.000000  \n",
       "mean         0.278044                 0.079029  \n",
       "std          0.042935                 0.011726  \n",
       "min          0.171200                 0.055210  \n",
       "25%          0.247200                 0.070210  \n",
       "50%          0.274700                 0.077730  \n",
       "75%          0.306400                 0.085510  \n",
       "max          0.412800                 0.115100  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling The Numerical Columns Using The MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding The Target Column Using Label Encoder\n",
    "encoder = LabelEncoder()\n",
    "df['diagnosis'] = encoder.fit_transform(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryaa\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m641\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m641\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_dim=30),\n",
    "    \n",
    "    Dense(8, activation='relu'),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5620 - loss: 0.6998 - val_accuracy: 0.6957 - val_loss: 0.6833\n",
      "Epoch 2/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7269 - loss: 0.6745 - val_accuracy: 0.7681 - val_loss: 0.6604\n",
      "Epoch 3/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7650 - loss: 0.6477 - val_accuracy: 0.7681 - val_loss: 0.6379\n",
      "Epoch 4/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7076 - loss: 0.6457 - val_accuracy: 0.7681 - val_loss: 0.6152\n",
      "Epoch 5/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7288 - loss: 0.6141 - val_accuracy: 0.7681 - val_loss: 0.5832\n",
      "Epoch 6/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7422 - loss: 0.5838 - val_accuracy: 0.7681 - val_loss: 0.5445\n",
      "Epoch 7/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.5373 - val_accuracy: 0.7681 - val_loss: 0.5133\n",
      "Epoch 8/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7034 - loss: 0.5539 - val_accuracy: 0.7681 - val_loss: 0.4888\n",
      "Epoch 9/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4966 - val_accuracy: 0.7681 - val_loss: 0.4566\n",
      "Epoch 10/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7568 - loss: 0.4994 - val_accuracy: 0.8116 - val_loss: 0.4338\n",
      "Epoch 11/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.4550 - val_accuracy: 0.8406 - val_loss: 0.4083\n",
      "Epoch 12/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.4389 - val_accuracy: 0.8696 - val_loss: 0.3838\n",
      "Epoch 13/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8184 - loss: 0.4208 - val_accuracy: 0.9565 - val_loss: 0.3649\n",
      "Epoch 14/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - loss: 0.4246 - val_accuracy: 0.9710 - val_loss: 0.3508\n",
      "Epoch 15/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.3897 - val_accuracy: 0.9710 - val_loss: 0.3307\n",
      "Epoch 16/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.3940 - val_accuracy: 0.9710 - val_loss: 0.3194\n",
      "Epoch 17/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.3593 - val_accuracy: 0.9710 - val_loss: 0.3036\n",
      "Epoch 18/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.3445 - val_accuracy: 0.9710 - val_loss: 0.2912\n",
      "Epoch 19/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.3267 - val_accuracy: 0.9710 - val_loss: 0.2803\n",
      "Epoch 20/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.3131 - val_accuracy: 0.9710 - val_loss: 0.2758\n",
      "Epoch 21/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.3226 - val_accuracy: 0.9710 - val_loss: 0.2557\n",
      "Epoch 22/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2941 - val_accuracy: 0.9710 - val_loss: 0.2434\n",
      "Epoch 23/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.2843 - val_accuracy: 0.9710 - val_loss: 0.2398\n",
      "Epoch 24/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.2891 - val_accuracy: 0.9710 - val_loss: 0.2283\n",
      "Epoch 25/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.2581 - val_accuracy: 0.9710 - val_loss: 0.2157\n",
      "Epoch 26/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.2478 - val_accuracy: 0.9710 - val_loss: 0.2083\n",
      "Epoch 27/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.2391 - val_accuracy: 0.9855 - val_loss: 0.2028\n",
      "Epoch 28/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9348 - loss: 0.2327 - val_accuracy: 0.9855 - val_loss: 0.1916\n",
      "Epoch 29/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.2420 - val_accuracy: 0.9855 - val_loss: 0.1802\n",
      "Epoch 30/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.2235 - val_accuracy: 0.9855 - val_loss: 0.1733\n",
      "Epoch 31/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1931 - val_accuracy: 0.9855 - val_loss: 0.1597\n",
      "Epoch 32/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.1724 - val_accuracy: 0.9855 - val_loss: 0.1577\n",
      "Epoch 33/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1906 - val_accuracy: 0.9855 - val_loss: 0.1610\n",
      "Epoch 34/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.1605 - val_accuracy: 0.9855 - val_loss: 0.1374\n",
      "Epoch 35/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.1778 - val_accuracy: 0.9855 - val_loss: 0.1427\n",
      "Epoch 36/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1643 - val_accuracy: 0.9855 - val_loss: 0.1351\n",
      "Epoch 37/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1606 - val_accuracy: 0.9855 - val_loss: 0.1224\n",
      "Epoch 38/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.1733 - val_accuracy: 0.9855 - val_loss: 0.1223\n",
      "Epoch 39/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1693 - val_accuracy: 0.9855 - val_loss: 0.1263\n",
      "Epoch 40/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9589 - loss: 0.1459 - val_accuracy: 0.9855 - val_loss: 0.1147\n",
      "Epoch 41/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.1498 - val_accuracy: 0.9855 - val_loss: 0.1079\n",
      "Epoch 42/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1467 - val_accuracy: 0.9855 - val_loss: 0.1094\n",
      "Epoch 43/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1450 - val_accuracy: 0.9855 - val_loss: 0.1088\n",
      "Epoch 44/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1396 - val_accuracy: 0.9855 - val_loss: 0.0997\n",
      "Epoch 45/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1334 - val_accuracy: 0.9855 - val_loss: 0.1021\n",
      "Epoch 46/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.1212 - val_accuracy: 0.9855 - val_loss: 0.0975\n",
      "Epoch 47/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.1258 - val_accuracy: 0.9855 - val_loss: 0.0940\n",
      "Epoch 48/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.1449 - val_accuracy: 0.9855 - val_loss: 0.0855\n",
      "Epoch 49/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1483 - val_accuracy: 0.9855 - val_loss: 0.0957\n",
      "Epoch 50/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1223 - val_accuracy: 0.9855 - val_loss: 0.0845\n",
      "Epoch 51/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1542 - val_accuracy: 0.9855 - val_loss: 0.0830\n",
      "Epoch 52/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.1010 - val_accuracy: 0.9855 - val_loss: 0.0881\n",
      "Epoch 53/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.1179 - val_accuracy: 0.9855 - val_loss: 0.0774\n",
      "Epoch 54/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1215 - val_accuracy: 0.9855 - val_loss: 0.0729\n",
      "Epoch 55/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.1193 - val_accuracy: 0.9855 - val_loss: 0.0781\n",
      "Epoch 56/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9565 - loss: 0.1188 - val_accuracy: 0.9855 - val_loss: 0.0786\n",
      "Epoch 57/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1051 - val_accuracy: 0.9855 - val_loss: 0.0653\n",
      "Epoch 58/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1165 - val_accuracy: 0.9855 - val_loss: 0.0776\n",
      "Epoch 59/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.1086 - val_accuracy: 0.9855 - val_loss: 0.0640\n",
      "Epoch 60/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.0842 - val_accuracy: 0.9855 - val_loss: 0.0656\n",
      "Epoch 61/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1070 - val_accuracy: 0.9855 - val_loss: 0.0732\n",
      "Epoch 62/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1135 - val_accuracy: 0.9855 - val_loss: 0.0663\n",
      "Epoch 63/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0841 - val_accuracy: 0.9855 - val_loss: 0.0622\n",
      "Epoch 64/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9343 - loss: 0.1280 - val_accuracy: 0.9855 - val_loss: 0.0660\n",
      "Epoch 65/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9522 - loss: 0.1114 - val_accuracy: 0.9855 - val_loss: 0.0582\n",
      "Epoch 66/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.1089 - val_accuracy: 0.9855 - val_loss: 0.0637\n",
      "Epoch 67/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.0811 - val_accuracy: 0.9855 - val_loss: 0.0629\n",
      "Epoch 68/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.0874 - val_accuracy: 0.9855 - val_loss: 0.0562\n",
      "Epoch 69/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 0.0838 - val_accuracy: 1.0000 - val_loss: 0.0637\n",
      "Epoch 70/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.0950 - val_accuracy: 1.0000 - val_loss: 0.0575\n",
      "Epoch 71/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0812 - val_accuracy: 0.9855 - val_loss: 0.0518\n",
      "Epoch 72/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.0860 - val_accuracy: 1.0000 - val_loss: 0.0635\n",
      "Epoch 73/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.0942 - val_accuracy: 1.0000 - val_loss: 0.0577\n",
      "Epoch 74/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9653 - loss: 0.0878 - val_accuracy: 0.9855 - val_loss: 0.0494\n",
      "Epoch 75/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.0893 - val_accuracy: 1.0000 - val_loss: 0.0525\n",
      "Epoch 76/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0869 - val_accuracy: 1.0000 - val_loss: 0.0520\n",
      "Epoch 77/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 0.0510\n",
      "Epoch 78/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.0950 - val_accuracy: 1.0000 - val_loss: 0.0465\n",
      "Epoch 79/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.0947 - val_accuracy: 1.0000 - val_loss: 0.0593\n",
      "Epoch 80/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0775 - val_accuracy: 1.0000 - val_loss: 0.0513\n",
      "Epoch 81/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.0917 - val_accuracy: 0.9855 - val_loss: 0.0412\n",
      "Epoch 82/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9597 - loss: 0.0911 - val_accuracy: 1.0000 - val_loss: 0.0534\n",
      "Epoch 83/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0802 - val_accuracy: 1.0000 - val_loss: 0.0480\n",
      "Epoch 84/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0461\n",
      "Epoch 85/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.0757 - val_accuracy: 1.0000 - val_loss: 0.0495\n",
      "Epoch 86/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0743 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
      "Epoch 87/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9703 - loss: 0.0895 - val_accuracy: 1.0000 - val_loss: 0.0461\n",
      "Epoch 88/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0405\n",
      "Epoch 89/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.0935 - val_accuracy: 1.0000 - val_loss: 0.0464\n",
      "Epoch 90/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.0752 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 91/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0767 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
      "Epoch 92/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0810 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
      "Epoch 93/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0754 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 94/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.0900 - val_accuracy: 1.0000 - val_loss: 0.0432\n",
      "Epoch 95/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9827 - loss: 0.0592 - val_accuracy: 1.0000 - val_loss: 0.0401\n",
      "Epoch 96/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.0934 - val_accuracy: 1.0000 - val_loss: 0.0415\n",
      "Epoch 97/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0386\n",
      "Epoch 98/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.0862 - val_accuracy: 1.0000 - val_loss: 0.0447\n",
      "Epoch 99/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
      "Epoch 100/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0675 - val_accuracy: 1.0000 - val_loss: 0.0387\n",
      "Epoch 101/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0669 - val_accuracy: 1.0000 - val_loss: 0.0411\n",
      "Epoch 102/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0607 - val_accuracy: 1.0000 - val_loss: 0.0386\n",
      "Epoch 103/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.0666 - val_accuracy: 1.0000 - val_loss: 0.0421\n",
      "Epoch 104/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.0707 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 105/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0568 - val_accuracy: 1.0000 - val_loss: 0.0453\n",
      "Epoch 106/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0872 - val_accuracy: 1.0000 - val_loss: 0.0388\n",
      "Epoch 107/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0772 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
      "Epoch 108/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0593 - val_accuracy: 1.0000 - val_loss: 0.0408\n",
      "Epoch 109/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9814 - loss: 0.0572 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 110/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0794 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
      "Epoch 111/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0593 - val_accuracy: 1.0000 - val_loss: 0.0343\n",
      "Epoch 112/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0523 - val_accuracy: 1.0000 - val_loss: 0.0434\n",
      "Epoch 113/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0645 - val_accuracy: 1.0000 - val_loss: 0.0354\n",
      "Epoch 114/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0478 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 115/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0347\n",
      "Epoch 116/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 0.0376\n",
      "Epoch 117/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0514 - val_accuracy: 1.0000 - val_loss: 0.0330\n",
      "Epoch 118/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
      "Epoch 119/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.0643 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
      "Epoch 120/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9731 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
      "Epoch 121/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0637 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 122/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0712 - val_accuracy: 1.0000 - val_loss: 0.0352\n",
      "Epoch 123/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
      "Epoch 124/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0391\n",
      "Epoch 125/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0527 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
      "Epoch 126/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
      "Epoch 127/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0599 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
      "Epoch 128/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9766 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 129/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 0.0629 - val_accuracy: 1.0000 - val_loss: 0.0306\n",
      "Epoch 130/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9881 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
      "Epoch 131/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0448 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
      "Epoch 132/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0547 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
      "Epoch 133/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9890 - loss: 0.0511 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
      "Epoch 134/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
      "Epoch 135/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0517 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
      "Epoch 136/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0518 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
      "Epoch 137/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
      "Epoch 138/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0682 - val_accuracy: 1.0000 - val_loss: 0.0264\n",
      "Epoch 139/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
      "Epoch 140/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0565 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
      "Epoch 141/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0496 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
      "Epoch 142/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0580 - val_accuracy: 1.0000 - val_loss: 0.0270\n",
      "Epoch 143/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0568 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
      "Epoch 144/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0577 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
      "Epoch 145/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0389 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
      "Epoch 146/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.0674 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
      "Epoch 147/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9834 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
      "Epoch 148/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0508 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
      "Epoch 149/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9814 - loss: 0.0638 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
      "Epoch 150/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0523 - val_accuracy: 1.0000 - val_loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0636 - val_accuracy: 1.0000 - val_loss: 0.0465\n",
      "Epoch 104/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.0969 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
      "Epoch 105/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.0651 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
      "Epoch 106/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9736 - loss: 0.0747 - val_accuracy: 1.0000 - val_loss: 0.0518\n",
      "Epoch 107/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0848 - val_accuracy: 1.0000 - val_loss: 0.0399\n",
      "Epoch 108/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
      "Epoch 109/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0516\n",
      "Epoch 110/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0738 - val_accuracy: 1.0000 - val_loss: 0.0393\n",
      "Epoch 111/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0375\n",
      "Epoch 112/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0658 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 113/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9725 - loss: 0.0674 - val_accuracy: 1.0000 - val_loss: 0.0418\n",
      "Epoch 114/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.0862 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
      "Epoch 115/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0847 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
      "Epoch 116/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0617 - val_accuracy: 1.0000 - val_loss: 0.0405\n",
      "Epoch 117/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0713 - val_accuracy: 1.0000 - val_loss: 0.0358\n",
      "Epoch 118/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.0816 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
      "Epoch 119/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.0767 - val_accuracy: 1.0000 - val_loss: 0.0352\n",
      "Epoch 120/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
      "Epoch 121/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.0850 - val_accuracy: 1.0000 - val_loss: 0.0365\n",
      "Epoch 122/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.0717 - val_accuracy: 1.0000 - val_loss: 0.0350\n",
      "Epoch 123/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0605 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 124/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
      "Epoch 125/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9618 - loss: 0.0805 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
      "Epoch 126/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.0700 - val_accuracy: 1.0000 - val_loss: 0.0330\n",
      "Epoch 127/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0634 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
      "Epoch 128/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9523 - loss: 0.0875 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
      "Epoch 129/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.0666 - val_accuracy: 1.0000 - val_loss: 0.0357\n",
      "Epoch 130/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0675 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
      "Epoch 131/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.0732 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
      "Epoch 132/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
      "Epoch 133/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 0.0714 - val_accuracy: 1.0000 - val_loss: 0.0335\n",
      "Epoch 134/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
      "Epoch 135/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0629 - val_accuracy: 1.0000 - val_loss: 0.0366\n",
      "Epoch 136/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.0626 - val_accuracy: 1.0000 - val_loss: 0.0326\n",
      "Epoch 137/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9765 - loss: 0.0528 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 138/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0311\n",
      "Epoch 139/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
      "Epoch 140/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9701 - loss: 0.0676 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 141/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9757 - loss: 0.0579 - val_accuracy: 1.0000 - val_loss: 0.0373\n",
      "Epoch 142/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.0668 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
      "Epoch 143/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.0710 - val_accuracy: 1.0000 - val_loss: 0.0355\n",
      "Epoch 144/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0578 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
      "Epoch 145/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9694 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
      "Epoch 146/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0699 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
      "Epoch 147/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9771 - loss: 0.0672 - val_accuracy: 1.0000 - val_loss: 0.0325\n",
      "Epoch 148/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.0536 - val_accuracy: 1.0000 - val_loss: 0.0288\n",
      "Epoch 149/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0537 - val_accuracy: 1.0000 - val_loss: 0.0357\n",
      "Epoch 150/150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0290\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63,  1],\n",
       "       [ 3, 19]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 180,
     "sourceId": 408,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
